#!/usr/bin/env python
"""
Using convnets to classify EEG images into four categories corresponding to four
WM load levels.
Implementation using Lasagne module.
Input images are scaled by divining by 256. No baseline correction.
EEG images are generated by extracting FFT power within theta, alpha and beta frequency bands.
Duration of experiment is divided into 5 parts (700ms each).
EEG images corresponding to each part is fed into a
"""
#from __future__ import print_function
import time

import numpy as np
np.random.seed(1234)
import scipy.io
import theano
import theano.tensor as T

import lasagne
# from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer
from lasagne.layers import Conv2DLayer, MaxPool2DLayer, InputLayer
from lasagne.layers import DenseLayer, ElemwiseMergeLayer, FlattenLayer
from lasagne.layers import ConcatLayer, ReshapeLayer, get_output_shape
from lasagne.layers import Conv1DLayer, DimshuffleLayer, LSTMLayer, SliceLayer
from utilsP import load_data, reformatInput, augment_EEG
from sklearn.preprocessing import normalize

augment = False                                 # Flag for data augmentation
init_pars = False                               # Initialize parameters from convnet
filename = 'EEG_images_32_timeWin'              # Name of the .mat file containing EEG images
filename_aug = 'EEG_images_32_timeWin_aug_pca'  # Name of the .mat file containing augmented EEG images
subjectsFilename = 'trials_subNums'             # Name of the .mat file containing trial/subject correspondence
model = 'mix'                                   # Model type selection
print('Model type is : {0}'.format(model))
num_epochs = 5                                  # Number of epochs for training
imSize = 32                                     # Size of the images
batch_size = 20                                 # Number of samples in each batch
nb_classes = 2                                  # Number of classes
numTimeWin = 7                                  # Number of time windows
GRAD_CLIP = 100                                 # Clipping value for gradient clipping in LSTM

augment = False                 # Augment data
pca = False                     # Augment using PCA
stdMult = 0.1                   # Standard deviation of added noise
n_components = 2                # Number of components to keep
#nGridPoints = 32                # Number of pixels in the image
nColors = 4                     # Number of color channels in the output image
nElectrodes = 32                # Number of electrodes





def gen_images(locs, features, nGridPoints, normalize=True,
               augment=False, pca=False, stdMult=0.1, n_components=2, edgeless=False):
    """
    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode

    :param loc: An array with shape [n_electrodes, 2] containing X, Y
                        coordinates for each electrode.
    :param features: Feature matrix as [n_samples, n_features+1]
                                Features are as columns.
                                Features corresponding to each frequency band are concatenated.
                                (alpha1, alpha2, ..., beta1, beta2,...)
    :param nGridPoints: Number of pixels in the output images
    :param normalize:   Flag for whether to normalize each feature over all samples
    :param augment:     Flag for generating augmented images
    :param pca:         Flag for PCA based data augmentation
    :param stdMult:     Standard deviation of noise for augmentation
    :param n_components:Number of components in PCA to retain for augmentation
    :param edgeless:    If True generates edgeless images by adding artificial channels
                        at four corners of the image with value = 0 (default=False).
    :return:            Tensor of size [samples, colors, W, H] containing generated
                        images.
    """

    feat_array_temp = []
    nElectrodes = locs.shape[0]     # Number of electrodes

    # Test whether the feature vector length is divisible by number of electrodes (last column is the labels)
    assert features.shape[1] % nElectrodes == 0
    n_colors = features.shape[1] / nElectrodes
    for c in range(n_colors):
        feat_array_temp.append(features[:, c * nElectrodes : nElectrodes * (c+1)])


    if augment:
        if pca:
            for c in range(n_colors):
                feat_array_temp[c] = augment_EEG(feat_array_temp[c], stdMult, pca=True, n_components=n_components)
        else:
            for c in range(n_colors):
                feat_array_temp[c] = augment_EEG(feat_array_temp[c], stdMult, pca=False, n_components=n_components)

    nSamples = features.shape[0]
    # Interpolate the values
    grid_x, grid_y = np.mgrid[
                     min(locs[:, 0]):max(locs[:, 0]):nGridPoints*1j,
                     min(locs[:, 1]):max(locs[:, 1]):nGridPoints*1j
                     ]
    temp_interp = []
    for c in range(n_colors):
        temp_interp.append(np.zeros([nSamples, nGridPoints, nGridPoints]))

    # Generate edgeless images
    if edgeless:
        min_x, min_y = np.min(locs, axis=0)
        max_x, max_y = np.max(locs, axis=0)
        locs = np.append(locs, np.array([[min_x, min_y], [min_x, max_y],[max_x, min_y],[max_x, max_y]]),axis=0)
        for c in range(n_colors):
            feat_array_temp[c] = np.append(feat_array_temp[c], np.zeros((nSamples, 4)), axis=1)

    for i in xrange(nSamples):
        for c in range(n_colors):
            temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),
                                    method='cubic', fill_value=np.nan)
        print 'Interpolating {0}/{1}\r'.format(i+1, nSamples),

    for c in range(n_colors):
        if normalize:
            temp_interp[c][~np.isnan(temp_interp[c])] = \
                scale(temp_interp[c][~np.isnan(temp_interp[c])])
        temp_interp[c] = np.nan_to_num(temp_interp[c])

    return np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H]


mat = scipy.io.loadmat('Neuroscan_locs_orig')
caploc=mat['A']
new=[]
for element in np.arange(0,caploc.shape[0]):
    #print "cc"
    new.append(caploc[element][0])
    new.append(caploc[element][1])
locs=np.asanyarray(new).reshape(32,2)
print locs
print 'ok'

images = gen_images(np.random.rand(10, 2),
                        np.random.rand(100, 31),
                        16, augment=True, pca=True, n_components=2)